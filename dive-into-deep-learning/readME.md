refer√™ncia: https://pt.d2l.ai/chapter_preface/index.html

## ü¶ñ Pref√°cio
Testar o potencial do deep learning apresenta desafios √∫nicos porque qualquer aplicativo re√∫ne v√°rias disciplinas. Aplicar o deep learning requer compreens√£o simult√¢nea (i) as motiva√ß√µes para definir um problema de uma maneira particular; (ii) a matem√°tica de uma dada abordagem de modelagem; (iii) os algoritmos de otimiza√ß√£o para ajustar os modelos aos dados; e (iv) a engenharia necess√°ria para treinar modelos de forma eficiente, navegando nas armadilhas da computa√ß√£o num√©rica e obter o m√°ximo do hardware dispon√≠vel. Ensinar as habilidades de pensamento cr√≠tico necess√°rias para formular problemas, a matem√°tica para resolv√™-los e as ferramentas de software para implementar tais solu√ß√µes em um s√≥ lugar apresentam desafios formid√°veis.

Propusemo-nos a criar um recurso que pudesse (i) estar dispon√≠vel gratuitamente para todos; (ii) oferecer profundidade t√©cnica suficiente para fornecer um ponto de partida no caminho para realmente se tornar um cientista de machine learning aplicado; (iii) incluir c√≥digo execut√°vel, mostrando aos leitores como resolver problemas na pr√°tica; (iv) permitir atualiza√ß√µes r√°pidas, tanto por n√≥s e tamb√©m pela comunidade em geral; e (v) ser complementado por um f√≥rum;

### Conte√∫do e Estrutura

![image](https://github.com/user-attachments/assets/e34d70ed-ba2a-4281-9620-b93e22502307)

√Äs vezes, para evitar repeti√ß√£o desnecess√°ria, encapsulamos as fun√ß√µes, classes, etc. importadas e mencionadas com frequ√™ncia neste livro no package d2l. Para qualquer bloco, como uma fun√ß√£o, uma classe ou v√°rios imports ser salvo no pacote, vamos marc√°-lo com # @ save. Oferecemos uma vis√£o geral detalhada dessas fun√ß√µes e classes em: numref: sec_d2l. O package d2l √© leve e requer apenas os seguintes packages e m√≥dulos como depend√™ncias:

```
#@save
import collections
import hashlib
import math
import os
import random
import re
import shutil
import sys
import tarfile
import time
import zipfile
from collections import defaultdict
import pandas as pd
import requests
from IPython import display
from matplotlib import pyplot as plt

d2l = sys.modules[__name__]
```

A maior parte do c√≥digo neste livro √© baseada no Apache MXNet. MXNet √© um framework de c√≥digo aberto (oper-source) para deep learning e a escolha preferida de AWS (Amazon Web Services), bem como muitas faculdades e empresas. Aqui est√° como importamos m√≥dulos do MXNet.
```
#@save
from mxnet import autograd, context, gluon, image, init, np, npx
from mxnet.gluon import nn, rnn
```

A maior parte do c√≥digo neste livro √© baseada no PyTorch. PyTorch √© uma estrutura de c√≥digo aberto para deep learning, que √© extremamente popular na comunidade de pesquisa. Aqui est√° como importamos m√≥dulos do PyTorch.
```
#@save
import numpy as np
import torch
import torchvision
from PIL import Image
from torch import nn
from torch.nn import functional as F
from torch.utils import data
from torchvision import transforms
```

A maior parte do c√≥digo deste livro √© baseada no TensorFlow. TensorFlow √© uma estrutura de c√≥digo aberto para deep learning, que √© extremamente popular na comunidade de pesquisa e na ind√∫stria. Aqui est√° como importamos m√≥dulos do TensorFlow.
```
#@save
import numpy as np
import tensorflow as tf
```

## ü¶ï Introdu√ß√£o
At√© recentemente, quase todos os programas de computador com os quais interagimos diariamente eram codificados por desenvolvedores de software desde os primeiros princ√≠pios. Digamos que quis√©ssemos escrever um aplicativo para gerenciar uma plataforma de e-commerce. Depois de se amontoar em um quadro branco por algumas horas para refletir sobre o problema, ir√≠amos apresentar os tra√ßos gerais de uma solu√ß√£o de trabalho que provavelmente se pareceria com isto: (i) os usu√°rios interagem com o aplicativo por meio de uma interface executando em um navegador da web ou aplicativo m√≥vel; (ii) nosso aplicativo interage com um mecanismo de banco de dados de n√≠vel comercial para acompanhar o estado de cada usu√°rio e manter registros de hist√≥rico de transa√ß√µes; e (iii) no cerne de nossa aplica√ß√£o, a l√≥gica de neg√≥cios (voc√™ pode dizer, os c√©rebros) de nosso aplicativo descreve em detalhes met√≥dicos a a√ß√£o apropriada que nosso programa deve levar em todas as circunst√¢ncias conceb√≠veis.

Para construir o c√©rebro de nosso aplicativo, ter√≠amos que percorrer todos os casos esquivos poss√≠veis que antecipamos encontrar, criando regras apropriadas. Cada vez que um cliente clica para adicionar um item ao carrinho de compras, adicionamos uma entrada √† tabela de banco de dados do carrinho de compras, associando o ID desse usu√°rio ao ID do produto solicitado. Embora poucos desenvolvedores acertem completamente na primeira vez (podem ser necess√°rios alguns testes para resolver os problemas), na maior parte, poder√≠amos escrever esse programa a partir dos primeiros princ√≠pios e lan√ß√°-lo com confian√ßa antes de ver um cliente real. Nossa capacidade de projetar sistemas automatizados a partir dos primeiros princ√≠pios que impulsionam o funcionamento de produtos, sistemas e, frequentemente em novas situa√ß√µes, √© um feito cognitivo not√°vel. E quando voc√™ √© capaz de conceber solu√ß√µes que funcionam do tempo, voc√™ n√£o deveria usar o machine learning.

Felizmente para a crescente comunidade de cientistas de machine learning, muitas tarefas que gostar√≠amos de automatizar n√£o se curvam t√£o facilmente √† habilidade humana. Imagine se amontoar em volta do quadro branco com as mentes mais inteligentes que voc√™ conhece, mas desta vez voc√™ est√° lidando com um dos seguintes problemas:

- Escreva um programa que preveja o clima de amanh√£ com base em informa√ß√µes geogr√°ficas, imagens de sat√©lite e uma janela de rastreamento do tempo passado.
- Escreva um programa que aceite uma pergunta, expressa em texto de forma livre, e a responda corretamente.
- Escreva um programa que, dada uma imagem, possa identificar todas as pessoas que ela cont√©m, desenhando contornos em torno de cada uma.
- Escreva um programa que apresente aos usu√°rios produtos que eles provavelmente ir√£o gostar, mas que provavelmente n√£o encontrar√£o no curso natural da navega√ß√£o.

Em cada um desses casos, mesmo programadores de elite s√£o incapazes de codificar solu√ß√µes do zero. As raz√µes para isso podem variar. √Äs vezes, o programa que procuramos segue um padr√£o que muda com o tempo, e precisamos que nossos programas se adaptem. Em outros casos, a rela√ß√£o (digamos, entre pixels, e categorias abstratas) podem ser muito complicadas, exigindo milhares ou milh√µes de c√°lculos que est√£o al√©m da nossa compreens√£o consciente mesmo que nossos olhos administrem a tarefa sem esfor√ßo. Machine learning √© o estudo de poderosas t√©cnicas que podem aprender com a experi√™ncia. √Ä medida que um algoritmo de machine learning acumula mais experi√™ncia, normalmente na forma de dados observacionais ou intera√ß√µes com um ambiente, seu desempenho melhora. Compare isso com nossa plataforma de com√©rcio eletr√¥nico determin√≠stica, que funciona de acordo com a mesma l√≥gica de neg√≥cios, n√£o importa quanta experi√™ncia acumule, at√© que os pr√≥prios desenvolvedores aprendam e decidam que √© hora de atualizar o software. Neste livro, ensinaremos os fundamentos do machine learning, e foco em particular no deep learning, um poderoso conjunto de t√©cnicas impulsionando inova√ß√µes em √°reas t√£o diversas como a vis√£o computacional, processamento de linguagem natural, sa√∫de e gen√¥mica.

### Um Exemplo motivador

Imagine apenas escrever um programa para responder a uma palavra de alerta como ‚ÄúAlexa‚Äù, ‚ÄúOK Google‚Äù e ‚ÄúHey Siri‚Äù. Tente codificar em uma sala sozinho com nada al√©m de um computador e um editor de c√≥digo. Como voc√™ escreveria tal programa a partir dos primeiros princ√≠pios? Pense nisso ‚Ä¶ o problema √© dif√≠cil. A cada segundo, o microfone ir√° coletar aproximadamente 44.000 amostras. Cada amostra √© uma medida da amplitude da onda sonora. Que regra poderia mapear de forma confi√°vel, de um trecho de √°udio bruto a previs√µes confi√°veis { yes, no } sobre se o trecho de √°udio cont√©m a palavra de ativa√ß√£o? Se voc√™ estiver travado, n√£o se preocupe. Tamb√©m n√£o sabemos escrever tal programa do zero. √â por isso que usamos o machine learning.

![image](https://github.com/user-attachments/assets/80b7346d-1fec-425c-8e73-dc617dd25a9d)


Aqui est√° o truque. Muitas vezes, mesmo quando n√£o sabemos como dizer a um computador explicitamente como mapear de entradas para sa√≠das, ainda assim, somos capazes de realizar a fa√ßanha cognitiva por n√≥s mesmos. Em outras palavras, mesmo que voc√™ n√£o saiba como programar um computador para reconhecer a palavra ‚ÄúAlexa‚Äù, voc√™ mesmo √© capaz de reconhec√™-lo. Armados com essa habilidade, podemos coletar um enorme dataset contendo exemplos de √°udio e rotular aqueles que cont√™m e que n√£o cont√™m a palavra de ativa√ß√£o. Na abordagem de machine learning, n√£o tentamos projetar um sistema explicitamente para reconhecer palavras de ativa√ß√£o. Em vez disso, definimos um programa flex√≠vel cujo comportamento √© determinado por v√°rios par√¢metros. Em seguida, usamos o conjunto de dados para determinar o melhor conjunto poss√≠vel de par√¢metros, aqueles que melhoram o desempenho do nosso programa com respeito a alguma medida de desempenho na tarefa de interesse.

Voc√™ pode pensar nos par√¢metros como bot√µes que podemos girar, manipulando o comportamento do programa. Fixando os par√¢metros, chamamos o programa de `modelo`. O conjunto de todos os programas distintos (mapeamentos de entrada-sa√≠da) que podemos produzir apenas manipulando os par√¢metros √© chamada de `fam√≠lia` de modelos. E o meta-programa que usa nosso conjunto de dados para escolher os par√¢metros √© chamado de `algoritmo de aprendizagem`.

Antes de prosseguirmos e envolvermos o algoritmo de aprendizagem, temos que definir o problema com precis√£o, identificando a natureza exata das entradas e sa√≠das, e escolher uma fam√≠lia modelo apropriada. Nesse caso, nosso modelo recebe um trecho de √°udio como `entrada`, e o modelo gera uma sele√ß√£o entre { yes, no } como `sa√≠da`. Se tudo correr de acordo com o plano as suposi√ß√µes da modelo v√£o normalmente estar corretas quanto a se o √°udio cont√©m a palavra de ativa√ß√£o.

Se escolhermos a fam√≠lia certa de modelos, deve haver uma configura√ß√£o dos bot√µes de forma que o modelo dispara ‚Äúsim‚Äù toda vez que ouve a palavra ‚ÄúAlexa‚Äù. Como a escolha exata da palavra de ativa√ß√£o √© arbitr√°ria, provavelmente precisaremos de uma fam√≠lia modelo suficientemente rica que, por meio de outra configura√ß√£o dos bot√µes, ele poderia disparar ‚Äúsim‚Äù somente ao ouvir a palavra ‚ÄúDamasco‚Äù. Esperamos que a mesma fam√≠lia de modelo seja adequada para reconhecimento ‚ÄúAlexa‚Äù e reconhecimento ‚ÄúDamasco‚Äù porque parecem, intuitivamente, tarefas semelhantes. No entanto, podemos precisar de uma fam√≠lia totalmente diferente de modelos se quisermos lidar com entradas ou sa√≠das fundamentalmente diferentes, digamos que se quis√©ssemos mapear de imagens para legendas, ou de frases em ingl√™s para frases em chin√™s.

Como voc√™ pode imaginar, se apenas definirmos todos os bot√µes aleatoriamente, √© improv√°vel que nosso modelo reconhe√ßa ‚ÄúAlexa‚Äù, ‚ÄúApricot‚Äù, ou qualquer outra palavra em ingl√™s. No machine learning, o aprendizado (learning) √© o processo pelo qual descobrimos a configura√ß√£o certa dos bot√µes coagindo o comportamento desejado de nosso modelo. Em outras palavras, n√≥s treinamos nosso modelo com dados. O processo de treinamento geralmente se parece com o seguinte:
1. Comece com um modelo inicializado aleatoriamente que n√£o pode fazer nada √∫til.
2. Pegue alguns de seus dados (por exemplo, trechos de √°udio e labels { yes, no } correspondentes).
3. Ajuste os bot√µes para que o modelo seja menos ruim em rela√ß√£o a esses exemplos.
4. Repita as etapas 2 e 3 at√© que o modelo esteja incr√≠vel.

![image](https://github.com/user-attachments/assets/29a97296-b1f2-4b1a-b9af-40fcd2c8e16f)

Para resumir, em vez de codificar um reconhecedor de palavra de acionamento, n√≥s codificamos um programa que pode aprender a reconhec√™-las se o apresentarmos com um grande dataset rotulado. Voc√™ pode pensar neste ato de determinar o comportamento de um programa apresentando-o com um __dataset como programa√ß√£o com dados__. Quer dizer, podemos ‚Äúprogramar‚Äù um detector de gatos, fornecendo nosso sistema de aprendizado de m√°quina com muitos exemplos de c√£es e gatos. Dessa forma, o detector aprender√° a emitir um n√∫mero positivo muito grande se for um gato, um n√∫mero negativo muito grande se for um cachorro, e algo mais pr√≥ximo de zero se n√£o houver certeza, e isso √© apenas a ponta do iceberg do que o machine learning pode fazer. Deep learning, que iremos explicar em maiores detalhes posteriormente, √© apenas um entre muitos m√©todos populares para resolver problemas de machine learning.

### Componentes chave

Em nosso exemplo de palavra de ativa√ß√£o, descrevemos um `dataset` consistindo em trechos de √°udio e labels bin√°rios, e n√≥s demos uma sensa√ß√£o ondulante de como podemos treinar um modelo para aproximar um mapeamento de √°udios para classifica√ß√µes. Esse tipo de problema, onde tentamos prever um `label` desconhecido designado com base em entradas conhecidas dado um conjunto de dados que consiste em exemplos para os quais os r√≥tulos s√£o conhecidos, √© chamado de `aprendizagem supervisionada`. Esse √© apenas um entre muitos tipos de problemas de machine learning. Posteriormente, mergulharemos profundamente em diferentes problemas de machine learning. Primeiro, gostar√≠amos de lan√ßar mais luz sobre alguns componentes principais que nos acompanhar√£o, independentemente do tipo de problema de machine learning que enfrentarmos:

1. Os `dados` com os quais podemos aprender.
2. Um `modelo` de como transformar os dados.
3. Uma `fun√ß√£o objetivo` que quantifica o qu√£o bem (ou mal) o modelo est√° indo.
4. Um `algoritmo` para ajustar os par√¢metros do modelo para otimizar a fun√ß√£o obejtivo.

#### Dados
Nem √© preciso dizer que voc√™ n√£o pode fazer ci√™ncia de dados sem dados. Podemos perder centenas de p√°ginas pensando no que exatamente constitui os dados, mas por agora, vamos errar no lado pr√°tico e focar nas principais propriedades com as quais se preocupar. Geralmente, estamos preocupados com uma cole√ß√£o de exemplos. Para trabalhar com dados de maneira √∫til, n√≥s tipicamente precisamos chegar a uma representa√ß√£o num√©rica adequada. Cada exemplo (__ou ponto de dados, inst√¢ncia de dados, amostra__) normalmente consiste em um conjunto de atributos chamados `recursos (ou covari√°veis)`, a partir do qual o modelo deve fazer suas previs√µes. Nos problemas de aprendizagem supervisionada acima, a coisa a prever √© um atributo especial que √© designado como o `r√≥tulo (label) (ou alvo)`.

Se estiv√©ssemos trabalhando com dados de imagem, cada fotografia individual pode constituir um exemplo, cada um representado por uma lista ordenada de valores num√©ricos correspondendo ao brilho de cada pixel. Uma fotografia colorida de 200 x 200 consistiria em 200 x 200 2 3 = 120000 valores num√©ricos, correspondentes ao brilho dos canais vermelho, verde e azul para cada pixel. Em outra tarefa tradicional, podemos tentar prever se um paciente vai sobreviver ou n√£o, dado um conjunto padr√£o de recursos, como idade, sinais vitais e diagn√≥sticos.

Quando cada exemplo √© caracterizado pelo mesmo n√∫mero de valores num√©ricos, dizemos que os dados consistem em vetores de comprimento fixo e descrevemos o comprimento constante dos vetores como a `dimensionalidade dos dados`. Como voc√™ pode imaginar, o comprimento fixo pode ser uma propriedade conveniente. Se quis√©ssemos treinar um modelo para reconhecer o c√¢ncer em imagens microsc√≥picas, entradas de comprimento fixo significam que temos uma coisa a menos com que nos preocupar.

No entanto, nem todos os dados podem ser facilmente representados como vetores de `comprimento fixo`. Embora possamos esperar que as imagens do microsc√≥pio venham de equipamentos padr√£o, n√£o podemos esperar imagens extra√≠das da Internet aparecerem todas com a mesma resolu√ß√£o ou formato. Para imagens, podemos considerar cort√°-los todas em um tamanho padr√£o, mas essa estrat√©gia s√≥ nos leva at√© certo ponto. Corremos o risco de perder informa√ß√µes nas partes cortadas. Al√©m disso, os dados de texto resistem a representa√ß√µes de comprimento fixo ainda mais obstinadamente. Considere os coment√°rios de clientes deixados em sites de com√©rcio eletr√¥nico como Amazon, IMDB e TripAdvisor. Alguns s√£o curtos: ‚Äú√© uma porcaria!‚Äù. Outros vagam por p√°ginas. Uma das principais vantagens do deep learning sobre os m√©todos tradicionais √© a gra√ßa comparativa com a qual os modelos modernos podem lidar com dados de `comprimento vari√°vel`.

Geralmente, quanto mais dados temos, mais f√°cil se torna nosso trabalho. Quando temos mais dados, podemos treinar modelos mais poderosos e dependem menos de suposi√ß√µes pr√©-concebidas. A mudan√ßa de regime de (comparativamente) pequeno para big data √© um dos principais contribuintes para o sucesso do deep learning moderno. Para esclarecer, muitos dos modelos mais interessantes de deep learning n√£o funcionam sem grandes datasets. Alguns outros trabalham no regime de pequenos dados, mas n√£o s√£o melhores do que as abordagens tradicionais.

Por fim, n√£o basta ter muitos dados e process√°-los com intelig√™ncia. Precisamos dos dados certos. Se os dados estiverem cheios de erros, ou se os recursos escolhidos n√£o s√£o preditivos da quantidade alvo de interesse, o aprendizado vai falhar. A situa√ß√£o √© bem capturada pelo clich√™: entra lixo, sai lixo. Al√©m disso, o desempenho preditivo ruim n√£o √© a √∫nica consequ√™ncia potencial. Em aplicativos sens√≠veis de machine learning, como policiamento preditivo, triagem de curr√≠culo e modelos de risco usados ‚Äã‚Äãpara empr√©stimos, devemos estar especialmente alertas para as consequ√™ncias de dados in√∫teis. Um modo de falha comum ocorre em conjuntos de dados onde alguns grupos de pessoas n√£o s√£o representados nos dados de treinamento. Imagine aplicar um sistema de reconhecimento de c√¢ncer de pele na natureza que nunca tinha visto pele negra antes. A falha tamb√©m pode ocorrer quando os dados n√£o apenas sub-representem alguns grupos mas refletem preconceitos sociais. Por exemplo, se as decis√µes de contrata√ß√£o anteriores forem usadas para treinar um modelo preditivo que ser√° usado para selecionar curr√≠culos, ent√£o os modelos de aprendizado de m√°quina poderiam inadvertidamente capturar e automatizar injusti√ßas hist√≥ricas. Observe que tudo isso pode acontecer sem o cientista de dados conspirar ativamente, ou mesmo estar ciente.

#### Modelos
A maior parte do machine learning envolve transformar os dados de alguma forma. Talvez queiramos construir um sistema que ingere fotos e preveja sorrisos. Alternativamente, podemos querer ingerir um conjunto de leituras de sensor e prever qu√£o normais ou an√¥malas s√£o as leituras. Por modelo, denotamos a maquinaria computacional para ingest√£o de dados de um tipo, e cuspir previs√µes de um tipo possivelmente diferente. Em particular, estamos interessados ‚Äã‚Äãem modelos estat√≠sticos que podem ser estimados a partir de dados. Embora os modelos simples sejam perfeitamente capazes de abordar problemas apropriadamente simples, os problemas nos quais nos concentramos neste livro, ampliam os limites dos m√©todos cl√°ssicos. O deep learning √© diferenciado das abordagens cl√°ssicas principalmente pelo conjunto de modelos poderosos em que se concentra. Esses modelos consistem em muitas transforma√ß√µes sucessivas dos dados que s√£o encadeados de cima para baixo, da√≠ o nome deep learning. No caminho para discutir modelos profundos, tamb√©m discutiremos alguns m√©todos mais tradicionais.


#### Fun√ß√µes Objetivo
Anteriormente, apresentamos o machine learning como aprendizado com a experi√™ncia. Por aprender aqui, queremos dizer melhorar em alguma tarefa ao longo do tempo. Mas quem pode dizer o que constitui uma melhoria? Voc√™ pode imaginar que poder√≠amos propor a atualiza√ß√£o do nosso modelo, e algumas pessoas podem discordar sobre se a atualiza√ß√£o proposta constituiu uma melhoria ou um decl√≠nio.

A fim de desenvolver um sistema matem√°tico formal de m√°quinas de aprendizagem, precisamos ter medidas formais de qu√£o bons (ou ruins) nossos modelos s√£o. No machine learning, e na otimiza√ß√£o em geral, chamamos elas de `fun√ß√µes objetivo`. Por conven√ß√£o, geralmente definimos fun√ß√µes objetivo de modo que quanto menor, melhor. Esta √© apenas uma conven√ß√£o. Voc√™ pode assumir qualquer fun√ß√£o para a qual mais alto √© melhor, e transform√°-la em uma nova fun√ß√£o que √© qualitativamente id√™ntica, mas para a qual menor √© melhor, invertendo o sinal. Porque quanto menor √© melhor, essas fun√ß√µes √†s vezes s√£o chamadas `fun√ß√µes de perda (loss functions)`.

Ao tentar prever valores num√©ricos, a fun√ß√£o de perda mais comum √© `erro quadr√°tico`, ou seja, o quadrado da diferen√ßa entre a previs√£o e a verdade fundamental. Para classifica√ß√£o, o objetivo mais comum √© minimizar a taxa de erro, ou seja, a fra√ß√£o de exemplos em que nossas previs√µes discordam da verdade fundamental. Alguns objetivos (por exemplo, erro quadr√°tico) s√£o f√°ceis de otimizar. Outros (por exemplo, taxa de erro) s√£o dif√≠ceis de otimizar diretamente, devido √† indiferenciabilidade ou outras complica√ß√µes. Nesses casos, √© comum otimizar um `objetivo substituto`.

Normalmente, a fun√ß√£o de perda √© definida no que diz respeito aos par√¢metros do modelo e depende do conjunto de dados. N√≥s aprendemos os melhores valores dos par√¢metros do nosso modelo minimizando a perda incorrida em um conjunto consistindo em alguns exemplos coletados para treinamento. No entanto, indo bem nos dados de treinamento n√£o garante que teremos um bom desempenho com dados n√£o vistos. Portanto, normalmente queremos dividir os dados dispon√≠veis em duas parti√ß√µes: o `dataset de treinamento` (ou conjunto de treinamento, para ajustar os par√¢metros do modelo) e o `dataset de teste` (ou conjunto de teste, que √© apresentado para avalia√ß√£o), relatando o desempenho do modelo em ambos. Voc√™ pode pensar no desempenho do treinamento como sendo as pontua√ß√µes de um aluno em exames pr√°ticos usado para se preparar para algum exame final real. Mesmo que os resultados sejam encorajadores, isso n√£o garante sucesso no exame final. Em outras palavras, o desempenho do teste pode divergir significativamente do desempenho do treinamento. Quando um modelo tem um bom desempenho no conjunto de treinamento mas falha em generalizar para dados invis√≠veis, dizemos que est√° fazendo `overfitting`. Em termos da vida real, √© como ser reprovado no exame real apesar de ir bem nos exames pr√°ticos.

#### Algoritmos de Otimiza√ß√£o
Assim que tivermos alguma fonte de dados e representa√ß√£o, um modelo e uma fun√ß√£o objetivo bem definida, precisamos de um algoritmo capaz de pesquisar para obter os melhores par√¢metros poss√≠veis para minimizar a fun√ß√£o de perda. Algoritmos de otimiza√ß√£o populares para aprendizagem profunda baseiam-se em uma abordagem chamada `gradiente descendente`. Em suma, em cada etapa, este m√©todo verifica, para cada par√¢metro, para que lado a perda do conjunto de treinamento se moveria se voc√™ perturbou esse par√¢metro apenas um pouco. Em seguida, atualiza o par√¢metro na dire√ß√£o que pode reduzir a perda.

### Tipos de Problemas de Machine Learning
O problema da palavra de ativa√ß√£o em nosso exemplo motivador √© apenas um entre muitos problemas que o machine learning pode resolver. Para motivar ainda mais o leitor e nos fornecer uma linguagem comum quando falarmos sobre mais problemas ao longo do livro, a seguir n√≥s listamos uma amostra dos problemas de machine learning. Estaremos constantemente nos referindo a nossos conceitos acima mencionados como dados, modelos e t√©cnicas de treinamento.

#### Aprendizagem Supervisionada
A aprendizagem supervisionada (supervised learning) aborda a tarefa de prever `labels` com recursos de entrada. Cada par recurso-r√≥tulo √© chamado de exemplo. √Äs vezes, quando o contexto √© claro, podemos usar o termo exemplos para se referir a uma cole√ß√£o de entradas, mesmo quando os labels correspondentes s√£o desconhecidos. Nosso objetivo √© produzir um modelo que mapeia qualquer entrada para uma previs√£o de label.

Para fundamentar esta descri√ß√£o em um exemplo concreto, se estiv√©ssemos trabalhando na √°rea de sa√∫de, ent√£o podemos querer prever se um paciente teria um ataque card√≠aco ou n√£o. Esta observa√ß√£o, ‚Äúataque card√≠aco‚Äù ou ‚Äúsem ataque card√≠aco‚Äù, seria nosso label. Os recursos de entrada podem ser sinais vitais como frequ√™ncia card√≠aca, press√£o arterial diast√≥lica, e press√£o arterial sist√≥lica.

A supervis√£o entra em jogo porque para a escolha dos par√¢metros, n√≥s (os supervisores) fornecemos ao modelo um conjunto de dados consistindo em exemplos rotulados, onde cada exemplo √© correspondido com o label da verdade fundamental. Em termos probabil√≠sticos, normalmente estamos interessados ‚Äã‚Äãem estimar a probabilidade condicional de determinados recursos de entrada de um label. Embora seja apenas um entre v√°rios paradigmas no machine learning, a aprendizagem supervisionada √© respons√°vel pela maioria das bem-sucedidas aplica√ß√µes de machine learning na ind√∫stria. Em parte, isso ocorre porque muitas tarefas importantes podem ser descritas nitidamente como estimar a probabilidade de algo desconhecido dado um determinado dataset dispon√≠vel:

- Prever c√¢ncer versus n√£o c√¢ncer, dada uma imagem de tomografia computadorizada.
- Prever a tradu√ß√£o correta em franc√™s, dada uma frase em ingl√™s.
- Prever o pre√ßo de uma a√ß√£o no pr√≥ximo m√™s com base nos dados de relat√≥rios financeiros deste m√™s.

Mesmo com a descri√ß√£o simples ‚Äúprevis√£o de labels com recursos de entrada‚Äù a aprendizagem supervisionada pode assumir muitas formas e exigem muitas decis√µes de modelagem, dependendo (entre outras considera√ß√µes) do tipo, tamanho, e o n√∫mero de entradas e sa√≠das. Por exemplo, usamos diferentes modelos para processar sequ√™ncias de comprimentos arbitr√°rios e para processar representa√ß√µes de vetores de comprimento fixo. Visitaremos muitos desses problemas em profundidade ao longo deste livro.

Informalmente, o processo de aprendizagem se parece com o seguinte. Primeiro, pegue uma grande cole√ß√£o de exemplos para os quais os recursos s√£o conhecidos e selecione deles um subconjunto aleat√≥rio, adquirindo os labels da verdade fundamental para cada um. √Äs vezes, esses labels podem ser dados dispon√≠veis que j√° foram coletados (por exemplo, um paciente morreu no ano seguinte?) e outras vezes, podemos precisar empregar anotadores humanos para rotular os dados, (por exemplo, atribui√ß√£o de imagens a categorias). Juntas, essas entradas e os labels correspondentes constituem o conjunto de treinamento. Alimentamos o dataset de treinamento em um algoritmo de aprendizado supervisionado, uma fun√ß√£o que recebe como entrada um conjunto de dados e produz outra fun√ß√£o: o modelo aprendido. Finalmente, podemos alimentar entradas n√£o vistas anteriormente para o modelo aprendido, usando suas sa√≠das como previs√µes do r√≥tulo correspondente.

![image](https://github.com/user-attachments/assets/1f9de33c-1212-4b63-8dec-2608f708409d)



<ins>Regress√£o</ins>

Talvez a tarefa de aprendizagem supervisionada mais simples para entender √© regress√£o. Considere, por exemplo, um conjunto de dados coletados de um banco de dados de vendas de casas. Podemos construir uma mesa, onde cada linha corresponde a uma casa diferente, e cada coluna corresponde a algum atributo relevante, como a metragem quadrada de uma casa, o n√∫mero de quartos, o n√∫mero de banheiros e o n√∫mero de minutos (caminhando) at√© o centro da cidade. Neste conjunto de dados, cada exemplo seria uma casa espec√≠fica, e o vetor de recurso correspondente seria uma linha na tabela. Se voc√™ mora em Nova York ou S√£o Francisco, e voc√™ n√£o √© o CEO da Amazon, Google, Microsoft ou Facebook, o vetor de recursos (metragem quadrada, n¬∫ de quartos, n¬∫ de banheiros, dist√¢ncia a p√©) para sua casa pode ser algo como: $ [56, 1, 1, 60] $. No entanto, se voc√™ mora em Pittsburgh, pode ser parecido com $ [279, 4, 3, 10] $. Vetores de recursos como este s√£o essenciais para a maioria dos algoritmos cl√°ssicos de machine learning.

O que torna um problema uma regress√£o √©, na verdade, o resultado. Digamos que voc√™ esteja em busca de uma nova casa. Voc√™ pode querer estimar o valor justo de mercado de uma casa, dados alguns recursos como acima. O label, o pre√ßo de venda, √© um valor num√©rico. Quando os labels assumem valores num√©ricos arbitr√°rios, chamamos isso de problema de regress√£o. Nosso objetivo √© produzir um modelo cujas previs√µes aproximar os valores reais do label.

Mesmo que voc√™ nunca tenha trabalhado com machine learning antes, voc√™ provavelmente j√° trabalhou em um problema de regress√£o informalmente. Imagine, por exemplo, que voc√™ mandou consertar seus ralos e que seu contratante gastou 3 horas removendo sujeira de seus canos de esgoto. Ent√£o ele lhe enviou uma conta de 350 d√≥lares. Agora imagine que seu amigo contratou o mesmo empreiteiro por 2 horas e que ele recebeu uma nota de 250 d√≥lares. Se algu√©m lhe perguntasse quanto esperar em sua pr√≥xima fatura de remo√ß√£o de sujeira voc√™ pode fazer algumas suposi√ß√µes razo√°veis, como mais horas trabalhadas custam mais d√≥lares. Voc√™ tamb√©m pode presumir que h√° alguma carga b√°sica e que o contratante cobra por hora. Se essas suposi√ß√µes forem verdadeiras, dados esses dois exemplos de dados, voc√™ j√° pode identificar a estrutura de pre√ßos do contratante: 100 d√≥lares por hora mais 50 d√≥lares para aparecer em sua casa. Se voc√™ acompanhou esse exemplo, ent√£o voc√™ j√° entendeu a ideia de alto n√≠vel por tr√°s da regress√£o linear.

Neste caso, poder√≠amos produzir os par√¢metros que correspondem exatamente aos pre√ßos do contratante. √Äs vezes isso n√£o √© poss√≠vel, por exemplo, se alguma varia√ß√£o se deve a algum fator al√©m dos dois citados. Nestes casos, tentaremos aprender modelos que minimizam a dist√¢ncia entre nossas previs√µes e os valores observados. Na maioria de nossos cap√≠tulos, vamos nos concentrar em minimizar a fun√ß√£o de perda de erro quadr√°tico. Como veremos mais adiante, essa perda corresponde ao pressuposto que nossos dados foram corrompidos pelo ru√≠do gaussiano.

<ins>Classifica√ß√£o</ins>

Embora os modelos de regress√£o sejam √≥timos para responder √†s quest√µes quantos?, muitos problemas n√£o se adaptam confortavelmente a este modelo. Por exemplo, um banco deseja adicionar a digitaliza√ß√£o de cheques ao seu aplicativo m√≥vel. Isso envolveria o cliente tirando uma foto de um cheque com a c√¢mera do smartphone deles e o aplicativo precisaria ser capaz de entender automaticamente o texto visto na imagem. Especificamente, tamb√©m precisaria entender o texto manuscrito para ser ainda mais robusto, como mapear um caractere escrito √† m√£o a um dos personagens conhecidos. Este tipo de problema de qual? √â chamado de classifica√ß√£o. √â tratado com um conjunto diferente de algoritmos do que aqueles usados ‚Äã‚Äãpara regress√£o, embora muitas t√©cnicas sejam transportadas.

Na classifica√ß√£o, queremos que nosso modelo analise os recursos, por exemplo, os valores de pixel em uma imagem, e, em seguida, prever qual `categoria` (formalmente chamada de classe), entre alguns conjuntos discretos de op√ß√µes, um exemplo pertence. Para d√≠gitos manuscritos, podemos ter dez classes, correspondendo aos d√≠gitos de 0 a 9. A forma mais simples de classifica√ß√£o √© quando existem apenas duas classes, um problema que chamamos de `classifica√ß√£o bin√°ria`. Por exemplo, nosso conjunto de dados pode consistir em imagens de animais e nossos r√≥tulos podem ser as classes { cat, dog }. Durante a regress√£o, buscamos um regressor para produzir um valor num√©rico, na classifica√ß√£o, buscamos um classificador, cuja sa√≠da √© a atribui√ß√£o de classe prevista.

Por raz√µes que abordaremos √† medida que o livro se torna mais t√©cnico, pode ser dif√≠cil otimizar um modelo que s√≥ pode produzir uma tarefa categ√≥rica dif√≠cil, por exemplo, ‚Äúgato‚Äù ou ‚Äúcachorro‚Äù. Nesses casos, geralmente √© muito mais f√°cil expressar nosso modelo na linguagem das probabilidades. Dados os recursos de um exemplo, nosso modelo atribui uma probabilidade para cada classe poss√≠vel. Voltando ao nosso exemplo de classifica√ß√£o animal onde as classes s√£o { gato, cachorro }, um classificador pode ver uma imagem e gerar a probabilidade que a imagem √© um gato como 0,9. Podemos interpretar esse n√∫mero dizendo que o classificador tem 90% de certeza de que a imagem representa um gato. A magnitude da probabilidade para a classe prevista transmite uma no√ß√£o de incerteza. Esta n√£o √© a √∫nica no√ß√£o de incerteza e discutiremos outros em cap√≠tulos mais avan√ßados.

Quando temos mais de duas classes poss√≠veis, chamamos o problema de `classifica√ß√£o multiclasse`. Exemplos comuns incluem reconhecimento de caracteres escritos √† m√£o { 0,1,2,...,9,a,b,c,... }. Enquanto atacamos problemas de regress√£o tentando minimizar a fun√ß√£o de perda de erro quadr√°tico, a fun√ß√£o de perda comum para problemas de classifica√ß√£o √© chamada de `entropia cruzada (cross-entropy)`, cujo nome pode ser desmistificado por meio de uma introdu√ß√£o √† teoria da informa√ß√£o nos cap√≠tulos subsequentes.
